gapminder %>% filter(continent=="Europe") %>% filter(year==1997) %>% arrange(gdpPercap)
gapminder %>% filter(year==1980)
gapminder %>% filter(year>=1980 & year<=1989)
gapminder %>% filter(year>=1980 & year<=1989) %>% select((lifeExp))
gapminder %>% filter(year>=1980 & year<=1989) %>% select((lifeExp))
mean(gapminder)
life <- gapminder %>% filter(year>=1980 & year<=1989) %>% select((lifeExp))
mean(life)
life <- gapminder %>% filter(year>=1980 & year<=1989) %>% select((lifeExp))
gapminder %>% filter(year>=1980 & year<=1989) %>% select((lifeExp)) %>% mean()
gapminder %>% filter(year>=1980 & year<=1989) %>% select(lifeExp) %>% mean()
gapminder %>% group_by(continet) %>% filter(year>=1980 & year<=1989) %>% select(lifeExp) %>% summarise(avg = mean(lifeExp,na.rm=TRUE))
gapminder %>% group_by(continent) %>% filter(year>=1980 & year<=1989) %>% select(lifeExp) %>% summarise(avg = mean(lifeExp,na.rm=TRUE))
gapminder %>% select(country,gpdPercap,pop) %>% gdpPercap*pop %>% group_by(country)
gapminder %>% group_by(country) %>% select(country,gdpPercap,pop) %>% summarise(total_gdp = gdpPercap*pop)
gapminder %>% group_by(country) %>% select(country,gdpPercap,pop) %>% gdpPercap*pop %>% sum()
gapminder %>% group_by(country) %>% select(country,gdpPercap,pop) %>% summarise(total_gpd = tally(gdpPercap*pop))
gapminder %>% group_by(country) %>% select(country,gdpPercap,pop) %>% summarise(total_gpd = (gdpPercap*pop)) %>% tally()
gapminder %>% group_by(country) %>% select(country,gdpPercap,pop) %>% transmute(total_gpd = tally(gdpPercap*pop))
gapminder %>% group_by(country) %>% select(country,gdpPercap,pop) %>% transmute(total_gdp = sum(gdpPercap*pop))
gapminder %>% group_by(country) %>% select(country,year,gdpPercap,pop) %>% mutate(total_gdp = sum(gdpPercap*pop))
gapminder %>% group_by(country) %>% select(country,year,gdpPercap,pop) %>% mutate(total_gdp = gdpPercap*pop)
gapminder %>% select(country,year,gdpPercap,pop) %>% group_by(country) %>% mutate(total_gdp = sum(gdpPercap*pop))
gapminder %>% select(country,year,gdpPercap,pop) %>% group_by(country) %>% summarise(total_gdp = sum(gdpPercap*pop), .groups='country')
gapminder %>% select(country,year,gdpPercap,pop) %>% group_by(country) %>% summarise(total_gdp = sum(gdpPercap*pop), .groups='drop')
gapminder %>% select(country,year,gdpPercap,pop) %>% group_by(country) %>% summarise(total_gdp = sum(gdpPercap*pop), .groups='drop') %>% desc()
gapminder %>% select(country,year,gdpPercap,pop) %>% group_by(country) %>% summarise(total_gdp = sum(gdpPercap*pop), .groups='drop') %>% arrange(total_gdp)
gapminder %>% select(country,year,gdpPercap,pop) %>% group_by(country) %>% summarise(total_gdp = sum(gdpPercap*pop), .groups='drop') %>% arrange(desc(total_gdp))
gapminder %>% select(country,year,lifeExp) %>% filter(lifeExp)
gapminder %>% select(country,year,lifeExp) %>% filter(lifeExp>=80)
out<-gapminder %>% select(country,year,lifeExp) %>% filter(lifeExp>=80)
print(out,n=nrow(out))
gapminder %>% select(country,pop) %>% group_by(country) %>% summarise(std_pop = sd(pop), .groups='drop') %>% arrange()
gapminder %>% select(country,pop) %>% group_by(country) %>% summarise(std_pop = sd(pop), .groups='drop') %>% arrange(std_pop)
country_asia <-gapminder %>% filter(continent=="Asia")
country_america <- gapminder %>% filter(continent=="Americas")
country_europe <- gapminder %>% filter(continent=="Europe")
country_ocean <- gapminder %>% filter(continent=="Oceania")
gapminder %>% select(continent,year,pop) %>% group_by(continent) %>% group_by(year) %>% summarise(avg_pop = mean(pop), .groups='drop') %>% arrange(desc(avg_pop))
gapminder %>% select(continent,year,pop) %>% group_by(continent) %>% group_by(year) %>% transmut(avg_pop = mean(pop), .groups='drop') %>% arrange(desc(avg_pop))
gapminder %>% select(continent,year,pop) %>% group_by(continent) %>% group_by(year) %>% transmute(avg_pop = mean(pop), .groups='drop') %>% arrange(desc(avg_pop))
gapminder %>% select(continent,year,pop) %>% group_by(continent,year) %>% summarise(avg_pop = mean(pop), .groups='drop') %>% arrange(desc(avg_pop))
gapminder %>% select(continent,year,pop) %>% group_by(continent,year) %>% summarise(avg_pop = mean(pop), .groups='drop') %>% filter(continent!='Asia') %>% arrange(desc(avg_pop))
install.packages("nycflights13")
library(nycflights13)
hourly_delay <- filter(
summarise(
group_by(
filter(
flights,
!is.na(dep_delay)
),
month, day, year, hour
),
delay=mean(dep_delay),
n=n()
),
n>10
)
View(hourly_delay)
View(hourly_delay)
hourly_delay
str(nycflights13)
hourly_delay2 <- filter(flights,!is.na(dep_delay)) %>% group_by(month,day,year hour) %>% summarise(dealy=mean(dep_delay),n=n()) %>% filter(n>10)
hourly_delay2 <- filter(flights,!is.na(dep_delay)) %>% group_by(month,day,year, hour) %>% summarise(dealy=mean(dep_delay),n=n()) %>% filter(n>10)
hourly_delay2
# Question 1: Find out the number of  countries
n_distinct(gapminder$country)
library(dplyr)
library(gapminder)
# Question 1: Find out the number of  countries
n_distinct(gapminder$country)
Bin(20,.025)
rbinom(50,20,.25)
table(data_bin) %>% prop.table()
library(dplyr)
table(data_bin) %>% prop.table()
data_bin <- rbinom(50,20,.25)
table(data_bin) %>% prop.table()
table(data_bin) %>% prop.test()
install.packages("dplyr")
library(dplyr)
# generate 50 random values from a Bin(20,.25) distribution
data_bin <- rbinom(50,20,.25)
# create and interpret a 90% confidence interval using z distribution
# conduct the mean of the data
mean_data_bin <- 20*.25
# conduct the variance of the data
var_data_bin = 20*(.25)*(1-.25)
# conduct the standard deviation of the data
std_data_bin <- sqrt(var_data_bin)
install.packages("dplyr")
library(dplyr)
# generate 50 random values from a Bin(20,.25) distribution
data_bin <- rbinom(50,20,.25)
# create and interpret a 90% confidence interval using z distribution
# conduct the mean of the data
mean_data_bin <- 20*.25
# conduct the variance of the data
var_data_bin = 20*(.25)*(1-.25)
# conduct the standard deviation of the data
std_data_bin <- sqrt(var_data_bin)
load("organic.rda")
load("C:\Users\klee232\Deaktop\organic.rda")
load("/Users/klee232/Deaktop/organic.rda")
load("../Users/klee232/Deaktop/organic.rda")
load("organic.rda")
load("C:/Users/klee232/Deaktop/organic.rda")
load("C:/Users/klee232/Deaktop/organic.rda")
load("/Users/klee232/Deaktop/organic.rda")
load("C:/Users/klee232/Deaktop/organic.rda")
load("organic.rda")
load(file="organic.rda")
getwd()
load("organic.rda")
View(organic)
data_prcess <- load("organic.rda")
load("organic.rda")
t.test(x=data_process_veggie,mu=2)
data_process_veggie <- organic$veggies
t.test(x=data_process_veggie,mu=2)
View(organic)
View(organic)
unique(organic$health)
good_health_data <- organix %>% filter(health=="Excellent" | health=="Very Good" | health=="Good")
good_health_data <- organic %>% filter(health=="Excellent" | health=="Very Good" | health=="Good")
bad_health_data <- organic %>% filter(health=="Fair" | health=="Poor")
View(bad_health_data)
View(bad_health_data)
good_health_data <- organic %>% filter(health=="Excellent" | health=="Very Good" | health=="Good")
bad_health_data <- organic %>% filter(health=="Fair" | health=="Poor")
# grab out veggies from good health people and bad health people
good_health_data_veggies <- good_health_data$veggies
bad_health_data_veggies <- bad_health_data$veggies
object.size(good_health_data_veggies)
length(good_health_data_veggies)
good_health_data_veggies
good_health_data_ind <- rep(1,length(good_health_data_veggies))
health_data_veggies <- c(good_health_data_veggies,bad_health_data_veggies)
test_data <- data.frame(health_data_veggies,health_ind)
health_ind <- c(good_health_data_ind,bad_health_data_ind)
# load data into work space
load("organic.rda")
# data is stored numerically in the variable "veggies".
data_process_veggie <- organic$veggies
t.test(x=data_process_veggie,mu=2)
# test the hypothesis that there is a significant difference in the mean veggies
# response between those who report being of at least good health vs those with
# less than good health
# divide the entire dataset based on health condition
good_health_data <- organic %>% filter(health=="Excellent" | health=="Very Good" | health=="Good")
bad_health_data <- organic %>% filter(health=="Fair" | health=="Poor")
# grab out veggies from good health people and bad health people
good_health_data_veggies <- good_health_data$veggies
bad_health_data_veggies <- bad_health_data$veggies
health_data_veggies <- c(good_health_data_veggies,bad_health_data_veggies)
# create a good health indicator
good_health_data_ind <- rep(1,length(good_health_data_veggies))
bad_health_data_ind <- rep(0,length(bad_health_data_veggies))
health_ind <- c(good_health_data_ind,bad_health_data_ind)
# create new tested data
test_data <- data.frame(health_data_veggies,health_ind)
View(test_data)
View(test_data)
t.test(health_data_veggies~health_ind,data=test_data,var.equal=F)
lower_confidence_interval,upper_confidence_interval
> lower_confidence_interval upper_confidence_interval
> lower_confidence_interval
lower_confidence_interval <- mean_data_bin + lower_bound*std_data_bin/sqrt(50)
# create and interpret a 90% confidence interval using z distribution
# conduct the mean of the data
mean_data_bin <- 20*.25
# conduct the variance of the data
var_data_bin = 20*(.25)*(1-.25)
# conduct the standard deviation of the data
std_data_bin <- sqrt(var_data_bin)
# conduct the criticial value for 90% confidence interval
lower_bound <- qnorm(0.05)
upper_bound <- qnorm(0.95)
# conduct the confidence interval value
lower_confidence_interval <- mean_data_bin + lower_bound*std_data_bin/sqrt(50)
upper_confidence_interval <- mean_data_bin + upper_bound*std_data_bin/sqrt(50)
lower_confidence_interval
upper_confidence_interval
# create and interpret a 90% confidence interval using t distribution
mean_data_bin_n <- mean(data_bin)
std_data_bin_n <- sd(data_bin)
n <- length(data_bin)
# conduct the critical value for 90% confidence interval
t_lower_bound <- qt(0.05, n-1)
t_upper_bound <- qt(0.95, n-1)
# conduct the confidence interval value
lower_t_confidence_interval <- mean_data_bin_n + t_lower_bound*std_data_bin_n/sqrt(50)
upper_t_confidence_interval <- mean_data_bin_n + t_upper_bound*std_data_bin_n/sqrt(50)
lower_t_confidence_interval
upper_t_confidence_interval
# load data into work space
load("organic.rda")
# data is stored numerically in the variable "veggies".
data_process_veggie <- organic$veggies
t.test(x=data_process_veggie,mu=2)
# test the hypothesis that there is a significant difference in the mean veggies
# response between those who report being of at least good health vs those with
# less than good health
# divide the entire dataset based on health condition
good_health_data <- organic %>% filter(health=="Excellent" | health=="Very Good" | health=="Good")
bad_health_data <- organic %>% filter(health=="Fair" | health=="Poor")
# grab out veggies from good health people and bad health people
good_health_data_veggies <- good_health_data$veggies
bad_health_data_veggies <- bad_health_data$veggies
health_data_veggies <- c(good_health_data_veggies,bad_health_data_veggies)
# create a good health indicator
good_health_data_ind <- rep(1,length(good_health_data_veggies))
bad_health_data_ind <- rep(0,length(bad_health_data_veggies))
health_ind <- c(good_health_data_ind,bad_health_data_ind)
# create new tested data
test_data <- data.frame(health_data_veggies,health_ind)
t.test(health_data_veggies~health_ind,data=test_data,var.equal=F)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse) # general data manipulation
library(tidyverse)
library(tableone)
library(GGally)
library(ggcorrplot)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse) # general data manipulation
library(tableone) # creating table summaries of the data
library(GGally) # pairwise scatterplots
library(ggcorrplot) # correlation plots
pain_df <- read.csv("pain.csv")
pain_df <- pain_df[sample(1:nrow(pain_df), 1000, replace=FALSE),]
dim(pain_df)
pain_df <- pain_df[,1:89]
tab1 <- CreateTableOne(vars = names(pain_df)[76:89],data=pain_df)
kableone(tab1)
# Exercise - try doing this for the body map variables - how are these reported?
summary(pain_df$PAIN_INTENSITY_AVERAGE) # summary of pain distribution
prop.table(table(pain_df$PAIN_INTENSITY_AVERAGE)) # treat as categorical
pain_df <- pain_df %>% filter(!is.na(PATIENT_NUM))
missing_vals <- apply(pain_df, 2, function(x) sum(is.na(x))/nrow(pain_df))
missing_vals[missing_vals > 0]
pain_df <- pain_df %>%
select(-c(GH_MENTAL_SCORE, GH_PHYSICAL_SCORE,
IMPRESSION_PAINCENTERIMPACT, IMPRESSION_TREATMENTIMPACT, BMI)) %>%
drop_na()
ggpairs(pain_df, columns=c(76:82))
corr <- round(cor(pain_df[,76:82]), 2)
ggcorrplot(corr, method="circle", type="upper", lab=TRUE)
pain_df$back_pain <- (pain_df$X218 == 1) | (pain_df$X219 == 1)
ggplot(pain_df)+geom_density(aes(x=PAIN_INTENSITY_AVERAGE, color=back_pain))
x <- 1:20
n <- length(x)
a <- 0.2
b <- 0.3
sigma <- 0.5
y <- a + b*x + sigma*rnorm(n)
fake <- data.frame(x,y)
head(fake)
mod <- lm(y~x, data=fake)
summary(mod)
plot(fake$x, fake$y)
a_hat <- coef(mod)[1] # first value - intercept
b_hat <- coef(mod)[2] # second value - slope
abline(a_hat, b_hat)
hibbs <- read.table("hibbs.dat", header=TRUE)
plot(hibbs$growth, hibbs$vote,
xlab="Average recent growth in personal income",
ylab="Incumbent party's vote share")
# FILL IN YOUR CODE
setwd("C:\Users\klee232\Desktop")
setwd("klee232\Desktop")
setwd("C:/Users/klee232/Desktop")
pain_df <- read.csv("pain.csv")
setwd("..")
setwd("/Desktop")
setwd("..")
getwd()
pain_df <- read.csv("pain.csv")
setwd("..")
getwd()
#pain_df <- read.csv("pain.csv")
#pain_df <- pain_df[sample(1:nrow(pain_df), 1000, replace=FALSE),]
#dim(pain_df)
pain_df <- read.csv("pain.csv")
pain_df <- pain_df[sample(1:nrow(pain_df), 1000, replace=FALSE),]
dim(pain_df)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
library(readxl) # import library for reading excel file
knitr::opts_chunk$set(echo = TRUE)
dataset_test <- read_excel("state_rep_laws.xlsx") # read in excel file for the dataset
knitr::opts_chunk$set(echo = TRUE)
pwd
knitr::opts_chunk$set(echo = TRUE)
getwd()
dataset_test <- read_excel("state_rep_laws.xlsx") # read in excel file for the dataset
knitr::opts_chunk$set(echo = TRUE)
dataset_test <- read_excel("state_rep_laws.xlsx") # read in excel file for the dataset
getwd()
dataset_test <- read_excel("state_rep_laws.xlsx") # read in excel file for the dataset
dataset_test <- read_excel("state_rep_laws.xlsx") # read in excel file for the dataset
getwd()
knitr::opts_chunk$set(echo = TRUE)
dataset_test <- read_excel("state_rep_laws.xlsx") # read in excel file for the dataset
knitr::opts_chunk$set(echo = TRUE)
getwd()
dataset_test <- read_excel("state_rep_laws.xlsx") # read in excel file for the dataset
knitr::opts_chunk$set(echo = TRUE)
getwd()
dataset_test <- read_excel("state_rep_laws") # read in excel file for the dataset
knitr::opts_chunk$set(echo = TRUE)
getwd()
dataset_test <- read,csvv("state_rep_laws.csv") # read in excel file for the dataset
knitr::opts_chunk$set(echo = TRUE)
getwd()
dataset_test <- read.csvv("state_rep_laws.csv") # read in excel file for the dataset
knitr::opts_chunk$set(echo = TRUE)
getwd()
dataset_test <- read.csv("state_rep_laws.csv") # read in excel file for the dataset
knitr::opts_chunk$set(echo = TRUE)
dataset_test <- read.csv("state_rep_laws.csv") # read in excel file for the dataset
dim(dataset_test)
knitr::opts_chunk$set(echo = TRUE)
dataset_test <- read.csv("state_rep_laws.csv") # read in excel file for the dataset
dim(dataset_test) # get the dimension of the dataset
get.vars(dataset_test)
knitr::opts_chunk$set(echo = TRUE)
dataset_test <- read.csv("state_rep_laws.csv") # read in excel file for the dataset
dim(dataset_test) # get the dimension of the dataset
dataset_test_vars <- colnames(dataset_test) # get the variable names in the dataset
dataset_test_vars
dataset_test_states <- dataset_test$state # extract out state variables
dataset_test_states <- unique(dataset_test_states) # eliminate duplicated state variables, show up only unique ones
dataset_test_states <- dataset_test$state # extract out state variables
dataset_test_states <- unique(dataset_test_states) # eliminate duplicated state variables, show up only unique ones
dataset_test_states
dataset_test_states <- dataset_test$state # extract out state variables
dataset_test_states <- unique(dataset_test_states) # eliminate duplicated state variables, show up only unique ones
num_dataset_test_states <- lenght(dataset_test_states) # get the number of states that publish out their data
dataset_test_states <- dataset_test$state # extract out state variables
dataset_test_states <- unique(dataset_test_states) # eliminate duplicated state variables, show up only unique ones
num_dataset_test_states <- length(dataset_test_states) # get the number of states that publish out their data
dataset_test_states
num_dataset_test_states
all_us_states = c("alabama", "alaska", "arizona", "arkansas",
"california", "colorado", "connecticut", "delaware", "district of columbia",
"florida", "georgia", "hawaii", "idaho", "illinois", "indiana",
"iowa", "kansas", "kentucky", "louisiana", "maine", "maryland",
"massachusetts", "michigan", "minnesota", "mississippi", "missouri",
"montana", "nebraska", "nevada", "new hampshire", "new jersey",
"new mexico", "new york", "north carolina", "north dakota", "ohio",
"oklahoma", "oregon", "pennsylvania", "rhode island", "south carolina",
"south dakota", "tennessee", "texas", "utah", "vermont", "virginia",
"washington", "west virginia", "wisconsin", "wyoming") # create a list of all US state names
not_dataset_test_states <-(all_us_states,dataset_test_states) # show out the states that are not available in the dataset
all_us_states = c("alabama", "alaska", "arizona", "arkansas",
"california", "colorado", "connecticut", "delaware", "district of columbia",
"florida", "georgia", "hawaii", "idaho", "illinois", "indiana",
"iowa", "kansas", "kentucky", "louisiana", "maine", "maryland",
"massachusetts", "michigan", "minnesota", "mississippi", "missouri",
"montana", "nebraska", "nevada", "new hampshire", "new jersey",
"new mexico", "new york", "north carolina", "north dakota", "ohio",
"oklahoma", "oregon", "pennsylvania", "rhode island", "south carolina",
"south dakota", "tennessee", "texas", "utah", "vermont", "virginia",
"washington", "west virginia", "wisconsin", "wyoming") # create a list of all US state names
not_dataset_test_states <-setdiff(all_us_states,dataset_test_states) # show out the states that are not available in the dataset
num_not_dataset_test_states <- length(not_dataset_test_states) # show out the number of states that are not available in the dataset
not_dataset_test_states
num_not_dataset_test_states
dataset_test_counties <- dataset_test$county # extract out county names in the dataset
dataset_test_women <- dataset_test$women # extract out the number of women in each county
dataset_test_abort <- dataset_test$abortion_count_2010 # extract out the number of abortion in each county
temp_dataset <- c(dataset_test_counties,dataset_test_women,dataset_test_abort) # form temporarily dataset for analysis
dataset_test_counties <- dataset_test$county # extract out county names in the dataset
dataset_test_women <- dataset_test$women # extract out the number of women in each county
dataset_test_abort <- dataset_test$abortion_count_2010 # extract out the number of abortion in each county
temp_dataset <- c(dataset_test_counties,dataset_test_women,dataset_test_abort) # form temporarily dataset for analysis
temp_dataset
dataset_test_counties <- dataset_test$county # extract out county names in the dataset
dataset_test_women <- dataset_test$women # extract out the number of women in each county
dataset_test_abort <- dataset_test$abortion_count_2010 # extract out the number of abortion in each county
temp_dataset <- c(dataset_test_counties,dataset_test_women,dataset_test_abort) # form temporarily dataset for analysis
colnames(temp_dataset) <- c("county","num_women","num_abort") # assign variable names to the table
dataset_test_counties <- dataset_test$county # extract out county names in the dataset
dataset_test_women <- dataset_test$women # extract out the number of women in each county
dataset_test_abort <- dataset_test$abortion_count_2010 # extract out the number of abortion in each county
temp_dataset <- data.frame(county = dataset_test_counties,
num_women = dataset_test_women,
num_abort = dataset_test_abort) # form temporarily dataset for analysis
View(temp_dataset)
View(temp_dataset)
abortions_per_women <- temp_dataset$num_abort/temp_dataset$num_women # calculation the abortions happen in each woman
abortions_per_women <- temp_dataset$num_abort/temp_dataset$num_women # calculation of the abortions happen in each woman
abortions_per_1000_women <- abortions_per_women*1000 # calculation of the abortions happen in every 1000 women
abortions_per_1000_women <- data.frame(abortions_per_1000_women = abortions_per_1000_women) # create a dataframe for the outcome
temp_dataset <- data.frame(temp_dataset,abortions_per_1000_women) # concatenate the outcome back to the temp table
dataset_test <- data.frame(dataset_test,abortions_per_1000_women) # concatenate the outcome back to the original table
names(highly_restrictive)
names(dataset_test$highly_restrictive)
dataset_test$highly_restrictive
dataset_test_restrict <- dataset_test$highly_restrictive # pull out the highly restrictive, which is defined as a binary variable of 0 represents as not, and 1 represents as yes
temp_dataset_restrictive <- data.frame(state=dataset_test_states,restrict=dataset_test_restrict) # create a temporarily table for storing
dataset_test_restrict <- dataset_test$highly_restrictive # pull out the highly restrictive, which is defined as a binary variable of 0 represents as not, and 1 represents as yes
temp_dataset_restrictive <- data.frame(state=dataset_test_states,restrict=dataset_test_restrict) # create a temporarily table for storing
dataset_test_all_states <- dataset_test$state # pull out all states in the dataset
dataset_test_restrict <- dataset_test$highly_restrictive # pull out the highly restrictive, which is defined as a binary variable of 0 represents as not, and 1 represents as yes
temp_dataset_restrictive <- data.frame(state=dataset_test_all_states,restrict=dataset_test_restrict) # create a temporarily table for storing
tab_restrictive <- CreateTableOne(vars = names(temp_dataset_restrictive)[2],data=temp_dataset_restrictive)
library(tableone)
dataset_test_all_states <- dataset_test$state # pull out all states in the dataset
dataset_test_restrict <- dataset_test$highly_restrictive # pull out the highly restrictive, which is defined as a binary variable of 0 represents as not, and 1 represents as yes
temp_dataset_restrictive <- data.frame(state=dataset_test_all_states,restrict=dataset_test_restrict) # create a temporarily table for storing
tab_restrictive <- CreateTableOne(vars = names(temp_dataset_restrictive)[2],data=temp_dataset_restrictive)
View(tab_restrictive)
View(tab_restrictive)
dataset_test_all_states <- dataset_test$state # pull out all states in the dataset
dataset_test_restrict <- dataset_test$highly_restrictive # pull out the highly restrictive, which is defined as a binary variable of 0 represents as not, and 1 represents as yes
temp_dataset_restrictive <- data.frame(state=dataset_test_all_states,restrict=dataset_test_restrict) # create a temporarily table for storing
tab_restrictive <- CreateTableOne(vars = names(temp_dataset_restrictive)[2],data=temp_dataset_restrictive)
kableone(tab_restrictive)
dataset_test_all_states <- dataset_test$state # pull out all states in the dataset
dataset_test_restrict <- dataset_test$highly_restrictive # pull out the highly restrictive, which is defined as a binary variable of 0 represents as not, and 1 represents as yes
temp_dataset_restrictive <- data.frame(state=dataset_test_all_states,restrict=dataset_test_restrict) # create a temporarily table for storing
tab_restrictive <- CreateTableOne(vars = names(temp_dataset_restrictive),strata=names(temp_dataset_restrictive)[2],data=temp_dataset_restrictive)
View(tab_restrictive)
View(tab_restrictive)
dataset_test_all_states <- dataset_test$state # pull out all states in the dataset
dataset_test_restrict <- dataset_test$highly_restrictive # pull out the highly restrictive, which is defined as a binary variable of 0 represents as not, and 1 represents as yes
temp_dataset_restrictive <- data.frame(state=dataset_test_all_states,restrict=dataset_test_restrict) # create a temporarily table for storing
tab_restrictive <- CreateTableOne(vars = names(temp_dataset_restrictive),strata=names(temp_dataset_restrictive)[2],data=temp_dataset_restrictive)
tab_restrictive
dataset_test_all_states <- dataset_test$state # pull out all states in the dataset
dataset_test_restrict <- dataset_test$highly_restrictive # pull out the highly restrictive, which is defined as a binary variable of 0 represents as not, and 1 represents as yes
temp_dataset_restrictive <- data.frame(state=dataset_test_all_states,restrict=dataset_test_restrict) # create a temporarily table for storing
tab_restrictive <- CreateTableOne(vars = names(temp_dataset_restrictive),strata=names(temp_dataset_restrictive)[2],data=temp_dataset_restrictive)
tab_restrictive$CatTable
dataset_test_all_states <- dataset_test$state # pull out all states in the dataset
dataset_test_restrict <- dataset_test$highly_restrictive # pull out the highly restrictive, which is defined as a binary variable of 0 represents as not, and 1 represents as yes
temp_dataset_restrictive <- data.frame(state=dataset_test_all_states,restrict=dataset_test_restrict) # create a temporarily table for storing
tab_restrictive <- CreateTableOne(vars = names(temp_dataset_restrictive),strata=names(temp_dataset_restrictive)[2],data=temp_dataset_restrictive)
summary(tab_restrictive$CatTable)
dataset_test_all_states <- dataset_test$state # pull out all states in the dataset
dataset_test_restrict <- dataset_test$highly_restrictive # pull out the highly restrictive, which is defined as a binary variable of 0 represents as not, and 1 represents as yes
temp_dataset_restrictive <- data.frame(state=dataset_test_all_states,restrict=dataset_test_restrict) # create a temporarily table for storing
tab_restrictive <- CreateTableOne(vars = names(temp_dataset_restrictive),strata=names(temp_dataset_restrictive)[2],data=temp_dataset_restrictive)
tab_restrictive$ContTable
dataset_test_all_states <- dataset_test$state # pull out all states in the dataset
dataset_test_restrict <- dataset_test$highly_restrictive # pull out the highly restrictive, which is defined as a binary variable of 0 represents as not, and 1 represents as yes
temp_dataset_restrictive <- data.frame(state=dataset_test_all_states,restrict=dataset_test_restrict) # create a temporarily table for storing
tab_restrictive <- CreateTableOne(vars = names(temp_dataset_restrictive),strata=names(temp_dataset_restrictive)[2],data=temp_dataset_restrictive)
tab_restrictive
dataset_test_all_states <- dataset_test$state # pull out all states in the dataset
dataset_test_restrict <- dataset_test$highly_restrictive # pull out the highly restrictive, which is defined as a binary variable of 0 represents as not, and 1 represents as yes
temp_dataset_restrictive <- data.frame(state=dataset_test_all_states,restrict=dataset_test_restrict) # create a temporarily table for storing
tab_restrictive <- CreateTableOne(vars = names(temp_dataset_restrictive)[1],strata=names(temp_dataset_restrictive)[2],data=temp_dataset_restrictive)
tab_restrictive
dataset_test_all_states <- dataset_test$state # pull out all states in the dataset
dataset_test_restrict <- dataset_test$highly_restrictive # pull out the highly restrictive, which is defined as a binary variable of 0 represents as not, and 1 represents as yes
temp_dataset_restrictive <- data.frame(state=dataset_test_all_states,restrict=dataset_test_restrict) # create a temporarily table for storing
tab_restrictive <- CreateTableOne(vars = names(temp_dataset_restrictive),strata=names(temp_dataset_restrictive)[2],data=temp_dataset_restrictive)
tab_restrictive
ratio_non_high <- 1486/2173*100
ratio_high <- 687/2173*100
ratio_non_high
ratio_high
grouped_data <- dataset_test %>% group_by(highly_restrictive)
library(tableone) # for tableone
library(dplyr) # for chaining operator
grouped_data <- dataset_test %>% group_by(highly_restrictive)
View(grouped_data)
View(grouped_data)
grouped_data <- dataset_test %>% group_by(highly_restrictive) # group data based on whether or not it's highly restrictive county
rest_data <- grouped_data %>% filter(highly_restrictive==1) # filter out
View(rest_data)
View(rest_data)
grouped_data <- dataset_test %>% group_by(highly_restrictive) # group data based on whether or not it's highly restrictive county
rest_data <- grouped_data %>% filter(highly_restrictive==1) # filter out only highly restrictive data
non_rest_data <- grouped_data %>% filter(highly_restrictive==0) # filter out only non highly restrictive data
ttest_women<-t.test(rest_data$women,non_rest_data$women)
View(ttest_women)
View(ttest_women)
t.test(rest_data$women,non_rest_data$women) # t test on the number of women residence
t.test(rest_data$women,non_rest_data$women) # t test on the number of women residence
t.test(rest_data$median_income,non_rest_data$median_income) # t test on the number of women residence
t.test(rest_data$democrat_2008,non_rest_data$democrat_2008) # t test on the number of vote for democrat in 2008
t.test(rest_data$abortion_count_2010,non_rest_data$abortion_count_2010) # t test on the number of abortion in 2010
t.test(rest_data$dist_to_closest_facility_miles,non_rest_data$dist_to_closest_facility_miles) # t test on the the distance to the closest facility providing abortions
library(tableone) # for tableone
library(dplyr) # for chaining operator
library(ggplot2) # for plotting purpose
View(dataset_test)
View(dataset_test)
ggplot(data=dataset_test,aes(x=highly_restrictive,y=abortions_per_1000_women))+geom_boxplot() # plot the boxplot for abortion per 1000 women based on whether it's a highly restrictive state or not
ggplot(dataset_test~highly_restrictive,aes(x=highly_restrictive,y=abortions_per_1000_women))+geom_boxplot() # plot the boxplot for abortion per 1000 women based on whether it's a highly restrictive state or not
ggplot(dataset_test,aes(x=as.factor(highly_restrictive),y=abortions_per_1000_women))+geom_boxplot() # plot the boxplot for abortion per 1000 women based on whether it's a highly restrictive state or not
ggplot(dataset_test,aes(x=as.factor(highly_restrictive),y=abortions_per_1000_women))+geom_boxplot() # plot the boxplot for abortion per 1000 women based on whether it's a highly restrictive state or not
ggplot(dataset_test,aes(x=as.factor(highly_restrictive),y=log(abortions_per_1000_women)))+geom_boxplot() # plot the boxplot for abortion per 1000 women based on whether it's a highly restrictive state or not
ggplot(dataset_test, aes(x=dist_to_closest_facility_miles, y=abortions_per_1000_women)) + geom_point() # create a scatter plot between the two variables: abortion per 1000 women and distance to the closest facility
ggplot(dataset_test, aes(x=median_income, y=abortions_per_1000_women)) + geom_point() # create a scatter plot between the two variables: abortion per 1000 women and median income
first_regression_mod <- lm(abortions_per_1000_women~highly_restrictive, data=dataset_test) # building up a regression model with highly restrictive indicator as predictor and abortions_per_1000_women as the response variables
summary(first_regression_mode)
first_regression_mod <- lm(abortions_per_1000_women~highly_restrictive, data=dataset_test) # building up a regression model with highly restrictive indicator as predictor and abortions_per_1000_women as the response variables
summary(first_regression_mod)
first_regression_mod <- lm(abortions_per_1000_women~factor(highly_restrictive), data=dataset_test) # building up a regression model with highly restrictive indicator as predictor and abortions_per_1000_women as the response variables
summary(first_regression_mod)
show_linear_regression_model<-2.624 +  (-0.362) * highly_restrictive + residual
library(tableone) # for tableone
library(dplyr) # for chaining operator
library(ggplot2) # for plotting purpose
second_regression_mod <- lm(abortions_per_1000_women~dist_to_closest_facility_miles, data=dataset_test) # building up a regression model with highly restrictive indicator as predictor and abortions_per_1000_women as the response variables
summary(second_regression_mod)
